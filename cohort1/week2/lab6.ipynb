{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "Advanced APIs for Scale - Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is the capital of Germany?\",\n",
    "    \"What is the capital of Italy?\",\n",
    "    \"What is the capital of Spain?\",\n",
    "    \"What is the capital of Portugal?\",\n",
    "    \"What is the capital of Greece?\",\n",
    "    \"What is the capital of Turkey?\",\n",
    "    \"What is the capital of Egypt?\",\n",
    "    \"What is the capital of South Africa?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step - Generate a jsonl file\n",
    "\n",
    "With this format:\n",
    "\n",
    "```jsonl\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-3.5-turbo-0125\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an unhelpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}],\"max_tokens\": 1000}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(index):\n",
    "    question = questions[index]\n",
    "    return f'{{\"custom_id\": \"request-{index}\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {{\"model\": \"gpt-4.1-nano\", \"messages\": [{{\"role\": \"user\", \"content\": \"{question}\"}}],\"max_tokens\": 1000}}}}'\n",
    "\n",
    "\n",
    "make_line(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"questions.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(questions)):\n",
    "        f.write(make_line(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step - upload the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions_file = openai.files.create(file=open(\"questions.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "questions_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step - make the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_id = questions_file.id\n",
    "batch = openai.batches.create(input_file_id=file_id, endpoint=\"/v1/chat/completions\", completion_window=\"24h\")\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step - monitor the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = openai.batches.retrieve(batch.id)\n",
    "print(latest)\n",
    "print(latest.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step - collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_id = latest.output_file_id\n",
    "results_file = openai.files.content(results_file_id)\n",
    "results_file.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lines = results_file.text.split(\"\\n\")\n",
    "results = [json.loads(line) for line in lines if line]\n",
    "print(f\"Number of results: {len(results)}\")\n",
    "print(\"First result:\")\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    id = result[\"custom_id\"]\n",
    "    question = questions[int(id.split(\"-\")[1])]\n",
    "    print(question)\n",
    "    print(result[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic has a similar Batch API\n",
    "\n",
    "https://docs.anthropic.com/en/docs/build-with-claude/batch-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
