{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70629249-1ff7-4638-8d44-5f07e67a071b",
   "metadata": {},
   "source": [
    "# Project 1 - Airline AI Assistant\n",
    "\n",
    "For this first project, we'll work on one of the very common use cases for Gen AI: a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d259d97-5061-43af-a641-3088c4df8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f0ff9-75ff-4d81-81c7-c36a05511151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716f24dc-ed56-4ac4-8b68-00554a186945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our chatbot we will select GPT-4.1-nano due to the price efficiency\n",
    "\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dd333-328c-4b3e-be58-a71b396fdc92",
   "metadata": {},
   "source": [
    "## Our first Assistant conversation\n",
    "\n",
    "We can call the API with a conversation - a list of dictionaries representing each interaction:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"essential instructions here, including tone\"},\n",
    "    {\"role\": \"user\", \"content\": \"a question from the user\"},\n",
    "    {\"role\": \"assistant\": \"content\": \"a response\"},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfc7248-ba02-4e00-9479-9435ec76721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, witty, humorous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7beff0-eb67-4892-aa39-351d98f96d40",
   "metadata": {},
   "source": [
    "And now we wrap this in a simple chat() function,  \n",
    "and then we use the shockingly simple Gradio platform to bring up a Chatbot UI.\n",
    "\n",
    "First, the chat function, which takes the current message and the history of prior messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a26c37-36a3-47d9-91ad-56c7c2489a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd056244-2326-4828-93d1-4af979715017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And look how complicated it is to launch a User Interface, with the fabulous gradio platform\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba266303-707d-4e06-882a-7323bdd812db",
   "metadata": {},
   "source": [
    "## Expertise\n",
    "\n",
    "We can give our model knowledge using the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fdcf2af-24ca-4d9d-a722-a6f62b623275",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \" In case it's relevant, the price of a return ticket to London is $799.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c8e7-fe1d-48ac-8245-9e01fd2980bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6861-1b58-4779-b525-5925a9aea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174aff0-b2d1-41cb-a93f-c371c8bbad76",
   "metadata": {},
   "source": [
    "## First steps towards agentic workflows\n",
    "\n",
    "Having multiple AIs collaborate to solve the problem is a simple step. Let's add another AI to the mix!\n",
    "\n",
    "Let's pick a fun one: adding multi-modality.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec51107b-50ac-4d6c-aa80-205694c3bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def artist_agent(city):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311244a0-9175-429f-9635-4023de705808",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = artist_agent(\"New York\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76e9be-70e5-47d7-bdc8-a484630c19a0",
   "metadata": {},
   "source": [
    "## Bringing it all together in a mini Agent Framework\n",
    "\n",
    "Bringing together both our LLM calls in 1 UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c832443b-8051-426f-a787-05f6f65ec84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    message = history[-1][\"content\"]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    image =  artist_agent(\"London\") if 'london' in message.lower() else None\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bdcb30-dfab-4a83-958c-702522f388f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=400, type=\"messages\")\n",
    "        image_output = gr.Image(height=400)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79b8fb-6c38-4034-b154-0a3f79e0572b",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just created a multi-modal AI Assistant\n",
    "\n",
    "### Simple Assignment\n",
    "\n",
    "Based on this code:\n",
    "\n",
    "```python\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"sydney\": \"$2999\"}\n",
    "```\n",
    "\n",
    "Allow the Chatbot to quote ticket prices for any of those destinations, and show images!\n",
    "\n",
    "## MAJOR ASSIGNMENT\n",
    "\n",
    "Make a variation of this Chatbot that applies this to your business\n",
    "\n",
    "\n",
    "### Optional Stretch Assignment for office hours\n",
    "\n",
    "Research \"tool use\" (also known as Function Calling) and then use this technique to add Tool capabilities to your LLM to look up ticket prices..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f6ff2-2f4e-4890-8ff6-df3077155b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"sydney\": \"$2999\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
